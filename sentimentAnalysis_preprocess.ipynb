{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentimentAnalysis_preprocess.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNsdYwInKZYJnR69ZAZPWgM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakibchowdhury131/sentimentAnalysisDL_v2.0/blob/main/sentimentAnalysis_preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiDZWXezEdcU",
        "outputId": "ce3d3e79-c5e7-4f77-f7d7-87213982b860"
      },
      "source": [
        "! git clone https://github.com/gitdevqiang/Covid-19-Sentiment-Analysis.git"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Covid-19-Sentiment-Analysis'...\n",
            "remote: Enumerating objects: 87, done.\u001b[K\n",
            "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
            "remote: Compressing objects: 100% (83/83), done.\u001b[K\n",
            "remote: Total 87 (delta 26), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (87/87), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zpCuJEAFABL",
        "outputId": "2199a9bf-855f-412a-9211-3d79b05993c6"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/Covid-19-Sentiment-Analysis/Dataset')\n",
        "os.listdir()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Covid-19-Sentiment-Analysis',\n",
              " 'train.csv',\n",
              " 'test_content.csv',\n",
              " 'val_content.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk-2iRaOFpVw"
      },
      "source": [
        "import pandas as pd\n",
        "def load_data(csv_file, columnNames = ['Tweet', 'Labels']): \n",
        "    dataset = pd.read_csv(csv_file)\n",
        "    return dataset[columnNames]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_f1X4BDGBLa"
      },
      "source": [
        "df = load_data('train.csv')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "MfYwMfrqGKZK",
        "outputId": "1f7e3d35-200a-4700-d9ca-0a12fc48414d"
      },
      "source": [
        "df[0:10]"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NO JOKE I WILL HOP ON A PLANE RN! (Well after ...</td>\n",
              "      <td>0 10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BanMediaHouse whose is responsible for spreadi...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Im waiting for someone to say to me that all t...</td>\n",
              "      <td>3 4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>He is a liar. Proven day night. Time again. Li...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NEW: U.S. CoronaVirus death toll reaches 4,000...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Coronavirus impact Govt extends I-T deadlines ...</td>\n",
              "      <td>5 8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>42,000 people might have died in China from Co...</td>\n",
              "      <td>6 7 8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Dear Chinese! Kindly cook your bat thoroughly ...</td>\n",
              "      <td>5 10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>This is how the govt of kenya is checking the ...</td>\n",
              "      <td>3 6 9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>My mental health hasn't suffered at all under ...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet Labels\n",
              "0  NO JOKE I WILL HOP ON A PLANE RN! (Well after ...   0 10\n",
              "1  BanMediaHouse whose is responsible for spreadi...      6\n",
              "2  Im waiting for someone to say to me that all t...    3 4\n",
              "3  He is a liar. Proven day night. Time again. Li...      6\n",
              "4  NEW: U.S. CoronaVirus death toll reaches 4,000...      8\n",
              "5  Coronavirus impact Govt extends I-T deadlines ...    5 8\n",
              "6  42,000 people might have died in China from Co...  6 7 8\n",
              "7  Dear Chinese! Kindly cook your bat thoroughly ...   5 10\n",
              "8  This is how the govt of kenya is checking the ...  3 6 9\n",
              "9  My mental health hasn't suffered at all under ...     10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkFUhWNKGLhb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32a10c46-581b-4127-db41-9371f2975e48"
      },
      "source": [
        "! pip install num2words\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: num2words in /usr/local/lib/python3.7/dist-packages (0.5.10)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words) (0.6.2)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsVXx0FdKPwY"
      },
      "source": [
        "corpus = []\n",
        "stop_words = set(stopwords.words('english'))\n",
        "for i in range (len(df)):\n",
        "  review = re.sub('[^a-zA-Z@]', ' ', df['Tweet'][i])\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "  bog = []\n",
        "  for j in range (len(review)):\n",
        "    if review[j].startswith('@') == False and not review[j] in stop_words:\n",
        "      bog.append(review[j])\n",
        "  bog = ' '.join(bog) \n",
        "  corpus.append(bog)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-oUqR3XKpXZ",
        "outputId": "5bc7e189-dffd-4b94-e445-1d03956aad5c"
      },
      "source": [
        "corpus[0:10]"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['joke hop plane rn well covid lol',\n",
              " 'banmediahouse whose responsible spreading fake communal stories pandemic corona situation',\n",
              " 'im waiting someone say corona thing april fools joke',\n",
              " 'liar proven day night time lies truth covid',\n",
              " 'new u coronavirus death toll reaches nearly new deaths reported today bno news covid coronavirusoutbreak',\n",
              " 'coronavirus impact govt extends deadlines related sections c',\n",
              " 'people might died china covid china underreporting according sources',\n",
              " 'dear chinese kindly cook bat thoroughly next time regards covid coronavirusupdates coronavirus',\n",
              " 'govt kenya checking temperatures covid saying still low mtashangaa sana',\n",
              " 'mental health suffered coronavirus quarantine ha ha april fools']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tRPHVlXLCL7",
        "outputId": "374f9f6b-40b9-4130-8c6c-53f3804ecbeb"
      },
      "source": [
        "print(len(df['Labels']))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNWPrxBXLDaO",
        "outputId": "9b8bc87e-a840-44e5-8dc1-52bd7aa3ffba"
      },
      "source": [
        "import numpy as np\n",
        "label = df['Labels'][0]\n",
        "label = label.split()\n",
        "print(label)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0', '10']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf-YUhjfMMXC"
      },
      "source": [
        "def processLabels(labelsDF):\n",
        "  num_class = 11\n",
        "  dfLen = len(labelsDF)\n",
        "  Y = np.zeros((dfLen, num_class), dtype = 'int')\n",
        "\n",
        "  for i in range(len(labelsDF)):\n",
        "    label = labelsDF[i]\n",
        "    label = label.split()\n",
        "    for word in label:\n",
        "      x = int(word)\n",
        "      Y[i, x] = 1\n",
        "  return Y\n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4KblsLNM7i4"
      },
      "source": [
        "Y = processLabels(labelsDF = df['Labels'])"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQuvFMnXSh1z"
      },
      "source": [
        "texts = corpus"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNED95lnSufk"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "tokens = []\n",
        "for line in texts:\n",
        "    words = word_tokenize(line)\n",
        "    tokens.append(words)\n",
        "\n",
        "tokenizer_obj = Tokenizer()\n",
        "tokenizer_obj.fit_on_texts(tokens)\n",
        "sequences = tokenizer_obj.texts_to_sequences(tokens)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpngH4CdTCfv",
        "outputId": "88526387-e6e9-4b6c-eb9c-32526576c6d6"
      },
      "source": [
        "tokens[0:10]"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['joke', 'hop', 'plane', 'rn', 'well', 'covid', 'lol'],\n",
              " ['banmediahouse',\n",
              "  'whose',\n",
              "  'responsible',\n",
              "  'spreading',\n",
              "  'fake',\n",
              "  'communal',\n",
              "  'stories',\n",
              "  'pandemic',\n",
              "  'corona',\n",
              "  'situation'],\n",
              " ['im',\n",
              "  'waiting',\n",
              "  'someone',\n",
              "  'say',\n",
              "  'corona',\n",
              "  'thing',\n",
              "  'april',\n",
              "  'fools',\n",
              "  'joke'],\n",
              " ['liar', 'proven', 'day', 'night', 'time', 'lies', 'truth', 'covid'],\n",
              " ['new',\n",
              "  'u',\n",
              "  'coronavirus',\n",
              "  'death',\n",
              "  'toll',\n",
              "  'reaches',\n",
              "  'nearly',\n",
              "  'new',\n",
              "  'deaths',\n",
              "  'reported',\n",
              "  'today',\n",
              "  'bno',\n",
              "  'news',\n",
              "  'covid',\n",
              "  'coronavirusoutbreak'],\n",
              " ['coronavirus',\n",
              "  'impact',\n",
              "  'govt',\n",
              "  'extends',\n",
              "  'deadlines',\n",
              "  'related',\n",
              "  'sections',\n",
              "  'c'],\n",
              " ['people',\n",
              "  'might',\n",
              "  'died',\n",
              "  'china',\n",
              "  'covid',\n",
              "  'china',\n",
              "  'underreporting',\n",
              "  'according',\n",
              "  'sources'],\n",
              " ['dear',\n",
              "  'chinese',\n",
              "  'kindly',\n",
              "  'cook',\n",
              "  'bat',\n",
              "  'thoroughly',\n",
              "  'next',\n",
              "  'time',\n",
              "  'regards',\n",
              "  'covid',\n",
              "  'coronavirusupdates',\n",
              "  'coronavirus'],\n",
              " ['govt',\n",
              "  'kenya',\n",
              "  'checking',\n",
              "  'temperatures',\n",
              "  'covid',\n",
              "  'saying',\n",
              "  'still',\n",
              "  'low',\n",
              "  'mtashangaa',\n",
              "  'sana'],\n",
              " ['mental',\n",
              "  'health',\n",
              "  'suffered',\n",
              "  'coronavirus',\n",
              "  'quarantine',\n",
              "  'ha',\n",
              "  'ha',\n",
              "  'april',\n",
              "  'fools']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNnAO0SBTa2q"
      },
      "source": [
        "def getMaxLen(tokens):\n",
        "  maxLen = 0\n",
        "  for token in tokens:\n",
        "    if len(token)>maxLen:\n",
        "      maxLen = len(token)\n",
        "\n",
        "  return maxLen\n",
        "  "
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yubHVdPnTEur",
        "outputId": "ed0d5f13-8365-4ae4-8c46-d41e2a700108"
      },
      "source": [
        "tokenizer_word_index = tokenizer_obj.word_index\n",
        "max_length = getMaxLen(tokens)\n",
        "print(max_length)\n",
        "review_pad = pad_sequences(sequences, maxlen = max_length)\n",
        "\n",
        "# train test split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(review_pad, Y, test_size = 0.20, random_state = 42)\n"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQ6auEajaOJV",
        "outputId": "b374799f-a1f1-429b-8ecf-0cbb085c19df"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    2,\n",
              "       1126,   93,  650,   70,  154,  798,   12,  186,   93,  585],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    }
  ]
}