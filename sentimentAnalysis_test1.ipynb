{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentimentAnalysis_test1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOdABpD4XqM5n1U+IIF885y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sakibchowdhury131/sentimentAnalysisDL_v2.0/blob/main/sentimentAnalysis_test1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiDZWXezEdcU",
        "outputId": "ce3d3e79-c5e7-4f77-f7d7-87213982b860"
      },
      "source": [
        "! git clone https://github.com/gitdevqiang/Covid-19-Sentiment-Analysis.git"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Covid-19-Sentiment-Analysis'...\n",
            "remote: Enumerating objects: 87, done.\u001b[K\n",
            "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
            "remote: Compressing objects: 100% (83/83), done.\u001b[K\n",
            "remote: Total 87 (delta 26), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (87/87), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zpCuJEAFABL",
        "outputId": "2199a9bf-855f-412a-9211-3d79b05993c6"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/Covid-19-Sentiment-Analysis/Dataset')\n",
        "os.listdir()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Covid-19-Sentiment-Analysis',\n",
              " 'train.csv',\n",
              " 'test_content.csv',\n",
              " 'val_content.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk-2iRaOFpVw"
      },
      "source": [
        "import pandas as pd\n",
        "def load_data(csv_file, columnNames = ['Tweet', 'Labels']): \n",
        "    dataset = pd.read_csv(csv_file)\n",
        "    return dataset[columnNames]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_f1X4BDGBLa"
      },
      "source": [
        "df = load_data('train.csv')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "MfYwMfrqGKZK",
        "outputId": "1f7e3d35-200a-4700-d9ca-0a12fc48414d"
      },
      "source": [
        "df[0:10]"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NO JOKE I WILL HOP ON A PLANE RN! (Well after ...</td>\n",
              "      <td>0 10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BanMediaHouse whose is responsible for spreadi...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Im waiting for someone to say to me that all t...</td>\n",
              "      <td>3 4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>He is a liar. Proven day night. Time again. Li...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NEW: U.S. CoronaVirus death toll reaches 4,000...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Coronavirus impact Govt extends I-T deadlines ...</td>\n",
              "      <td>5 8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>42,000 people might have died in China from Co...</td>\n",
              "      <td>6 7 8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Dear Chinese! Kindly cook your bat thoroughly ...</td>\n",
              "      <td>5 10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>This is how the govt of kenya is checking the ...</td>\n",
              "      <td>3 6 9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>My mental health hasn't suffered at all under ...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Tweet Labels\n",
              "0  NO JOKE I WILL HOP ON A PLANE RN! (Well after ...   0 10\n",
              "1  BanMediaHouse whose is responsible for spreadi...      6\n",
              "2  Im waiting for someone to say to me that all t...    3 4\n",
              "3  He is a liar. Proven day night. Time again. Li...      6\n",
              "4  NEW: U.S. CoronaVirus death toll reaches 4,000...      8\n",
              "5  Coronavirus impact Govt extends I-T deadlines ...    5 8\n",
              "6  42,000 people might have died in China from Co...  6 7 8\n",
              "7  Dear Chinese! Kindly cook your bat thoroughly ...   5 10\n",
              "8  This is how the govt of kenya is checking the ...  3 6 9\n",
              "9  My mental health hasn't suffered at all under ...     10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkFUhWNKGLhb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32a10c46-581b-4127-db41-9371f2975e48"
      },
      "source": [
        "! pip install num2words\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: num2words in /usr/local/lib/python3.7/dist-packages (0.5.10)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words) (0.6.2)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsVXx0FdKPwY"
      },
      "source": [
        "corpus = []\n",
        "\n",
        "for i in range (len(df)):\n",
        "  review = re.sub('[^a-zA-Z@]', ' ', df['Tweet'][i])\n",
        "\n",
        "  review = review.lower()\n",
        "  review = review.split()\n",
        "  bog = []\n",
        "  for j in range (len(review)):\n",
        "    if review[j].startswith('@') == False:\n",
        "      bog.append(review[j])\n",
        "  bog = ' '.join(bog) \n",
        "  corpus.append(bog)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-oUqR3XKpXZ",
        "outputId": "196b18ae-72d7-4f11-efcb-6cf98eef44fa"
      },
      "source": [
        "corpus[0:10]"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['no joke i will hop on a plane rn well after covid lol',\n",
              " 'banmediahouse whose is responsible for spreading fake and communal stories in this pandemic corona situation',\n",
              " 'im waiting for someone to say to me that all this corona thing is just an april fools joke',\n",
              " 'he is a liar proven day night time again lies when the truth will do covid',\n",
              " 'new u s coronavirus death toll reaches after nearly new deaths were reported today bno news covid coronavirusoutbreak',\n",
              " 'coronavirus impact govt extends i t deadlines related to sections c d',\n",
              " 'people might have died in china from covid but china was underreporting according to sources',\n",
              " 'dear chinese kindly cook your bat thoroughly next time regards covid coronavirusupdates coronavirus',\n",
              " 'this is how the govt of kenya is checking the temperatures of covid and saying it is still low mtashangaa sana',\n",
              " 'my mental health hasn t suffered at all under the coronavirus quarantine ha ha april fools']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tRPHVlXLCL7",
        "outputId": "18bdf319-1cb0-4e55-ed3a-ec843cd90348"
      },
      "source": [
        "print(len(df['Labels']))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNWPrxBXLDaO",
        "outputId": "3e19eccb-9209-45a9-8326-095e7b546013"
      },
      "source": [
        "import numpy as np\n",
        "label = df['Labels'][0]\n",
        "label = label.split()\n",
        "print(label)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0', '10']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf-YUhjfMMXC"
      },
      "source": [
        "def processLabels(labelsDF):\n",
        "  num_class = 11\n",
        "  dfLen = len(labelsDF)\n",
        "  Y = np.zeros((dfLen, num_class), dtype = 'int')\n",
        "\n",
        "  for i in range(len(labelsDF)):\n",
        "    label = labelsDF[i]\n",
        "    label = label.split()\n",
        "    for word in label:\n",
        "      x = int(word)\n",
        "      Y[i, x] = 1\n",
        "  return Y\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4KblsLNM7i4"
      },
      "source": [
        "Y = processLabels(labelsDF = df['Labels'])"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQuvFMnXSh1z"
      },
      "source": [
        "texts = corpus"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNED95lnSufk"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "tokens = []\n",
        "for line in texts:\n",
        "    words = word_tokenize(line)\n",
        "    tokens.append(words)\n",
        "\n",
        "tokenizer_obj = Tokenizer()\n",
        "tokenizer_obj.fit_on_texts(tokens)\n",
        "sequences = tokenizer_obj.texts_to_sequences(tokens)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpngH4CdTCfv",
        "outputId": "9be976f4-ff17-49a5-c3bc-84cec9f44d3a"
      },
      "source": [
        "tokens[0:10]"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['no',\n",
              "  'joke',\n",
              "  'i',\n",
              "  'will',\n",
              "  'hop',\n",
              "  'on',\n",
              "  'a',\n",
              "  'plane',\n",
              "  'rn',\n",
              "  'well',\n",
              "  'after',\n",
              "  'covid',\n",
              "  'lol'],\n",
              " ['banmediahouse',\n",
              "  'whose',\n",
              "  'is',\n",
              "  'responsible',\n",
              "  'for',\n",
              "  'spreading',\n",
              "  'fake',\n",
              "  'and',\n",
              "  'communal',\n",
              "  'stories',\n",
              "  'in',\n",
              "  'this',\n",
              "  'pandemic',\n",
              "  'corona',\n",
              "  'situation'],\n",
              " ['im',\n",
              "  'waiting',\n",
              "  'for',\n",
              "  'someone',\n",
              "  'to',\n",
              "  'say',\n",
              "  'to',\n",
              "  'me',\n",
              "  'that',\n",
              "  'all',\n",
              "  'this',\n",
              "  'corona',\n",
              "  'thing',\n",
              "  'is',\n",
              "  'just',\n",
              "  'an',\n",
              "  'april',\n",
              "  'fools',\n",
              "  'joke'],\n",
              " ['he',\n",
              "  'is',\n",
              "  'a',\n",
              "  'liar',\n",
              "  'proven',\n",
              "  'day',\n",
              "  'night',\n",
              "  'time',\n",
              "  'again',\n",
              "  'lies',\n",
              "  'when',\n",
              "  'the',\n",
              "  'truth',\n",
              "  'will',\n",
              "  'do',\n",
              "  'covid'],\n",
              " ['new',\n",
              "  'u',\n",
              "  's',\n",
              "  'coronavirus',\n",
              "  'death',\n",
              "  'toll',\n",
              "  'reaches',\n",
              "  'after',\n",
              "  'nearly',\n",
              "  'new',\n",
              "  'deaths',\n",
              "  'were',\n",
              "  'reported',\n",
              "  'today',\n",
              "  'bno',\n",
              "  'news',\n",
              "  'covid',\n",
              "  'coronavirusoutbreak'],\n",
              " ['coronavirus',\n",
              "  'impact',\n",
              "  'govt',\n",
              "  'extends',\n",
              "  'i',\n",
              "  't',\n",
              "  'deadlines',\n",
              "  'related',\n",
              "  'to',\n",
              "  'sections',\n",
              "  'c',\n",
              "  'd'],\n",
              " ['people',\n",
              "  'might',\n",
              "  'have',\n",
              "  'died',\n",
              "  'in',\n",
              "  'china',\n",
              "  'from',\n",
              "  'covid',\n",
              "  'but',\n",
              "  'china',\n",
              "  'was',\n",
              "  'underreporting',\n",
              "  'according',\n",
              "  'to',\n",
              "  'sources'],\n",
              " ['dear',\n",
              "  'chinese',\n",
              "  'kindly',\n",
              "  'cook',\n",
              "  'your',\n",
              "  'bat',\n",
              "  'thoroughly',\n",
              "  'next',\n",
              "  'time',\n",
              "  'regards',\n",
              "  'covid',\n",
              "  'coronavirusupdates',\n",
              "  'coronavirus'],\n",
              " ['this',\n",
              "  'is',\n",
              "  'how',\n",
              "  'the',\n",
              "  'govt',\n",
              "  'of',\n",
              "  'kenya',\n",
              "  'is',\n",
              "  'checking',\n",
              "  'the',\n",
              "  'temperatures',\n",
              "  'of',\n",
              "  'covid',\n",
              "  'and',\n",
              "  'saying',\n",
              "  'it',\n",
              "  'is',\n",
              "  'still',\n",
              "  'low',\n",
              "  'mtashangaa',\n",
              "  'sana'],\n",
              " ['my',\n",
              "  'mental',\n",
              "  'health',\n",
              "  'hasn',\n",
              "  't',\n",
              "  'suffered',\n",
              "  'at',\n",
              "  'all',\n",
              "  'under',\n",
              "  'the',\n",
              "  'coronavirus',\n",
              "  'quarantine',\n",
              "  'ha',\n",
              "  'ha',\n",
              "  'april',\n",
              "  'fools']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNnAO0SBTa2q"
      },
      "source": [
        "def getMaxLen(tokens):\n",
        "  maxLen = 0\n",
        "  for token in tokens:\n",
        "    if len(token)>maxLen:\n",
        "      maxLen = len(token)\n",
        "\n",
        "  return maxLen\n",
        "  "
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yubHVdPnTEur",
        "outputId": "74155a58-04c3-4fb3-a96d-a7d940cf791b"
      },
      "source": [
        "tokenizer_word_index = tokenizer_obj.word_index\n",
        "max_length = getMaxLen(tokens)\n",
        "print(max_length)\n",
        "review_pad = pad_sequences(sequences, maxlen = max_length)\n",
        "\n",
        "# train test split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(review_pad, Y, test_size = 0.20, random_state = 42)\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}